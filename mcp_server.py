#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¾é£Ÿæ¨èMCPæœåŠ¡å™¨
åŸºäºFastMCPæ¡†æ¶å’Œç™¾åº¦åœ°å›¾APIæ„å»ºçš„æ™ºèƒ½é¤å…æ¨èç³»ç»Ÿ
"""

import os
import httpx
import asyncio
import logging
import math
import re
from typing import List, Dict, Any, Optional, Union
from dotenv import load_dotenv
from fastmcp import FastMCP
from functools import lru_cache
import time
from datetime import datetime, timedelta
import threading
import http.client
from http.server import BaseHTTPRequestHandler, HTTPServer

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("food_mcp.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
API_KEY = os.getenv("BAIDU_MAPS_API_KEY", "")
if not API_KEY or API_KEY == "your_actual_baidu_maps_api_key_here" or API_KEY == "your_actual_api_key_here" or API_KEY == "BAIDU_MAPS_API_KEY":
    logger.error("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ BAIDU_MAPS_API_KEY ä¸ºä½ çš„ç™¾åº¦åœ°å›¾ API Key")
    logger.error("å½“å‰çš„ API Key æ˜¯æ— æ•ˆçš„: %s", API_KEY)
    logger.error("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®æ­£ç¡®çš„ç™¾åº¦åœ°å›¾ API Key")
    raise RuntimeError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ BAIDU_MAPS_API_KEY ä¸ºä½ çš„ç™¾åº¦åœ°å›¾ API Key")

API_URL = "https://api.map.baidu.com"

# åˆ›å»ºå…¨å±€ HTTP å®¢æˆ·ç«¯å®ä¾‹ä»¥å¤ç”¨è¿æ¥
http_client = httpx.AsyncClient(timeout=30.0)

# åˆ›å»º FastMCP æœåŠ¡å™¨å®ä¾‹
mcp = FastMCP("food-recommender")

# ç”¨æˆ·è¯„ä»·å­˜å‚¨ï¼ˆåœ¨å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨æ•°æ®åº“ï¼‰
user_reviews = {}


def haversine_distance(lat1: float, lon1: float, lat2: float, lon2: float) -> float:
    """
    ä½¿ç”¨ Haversine å…¬å¼è®¡ç®—ä¸¤ä¸ªç»çº¬åº¦ç‚¹ä¹‹é—´çš„è·ç¦»ï¼ˆå•ä½ï¼šç±³ï¼‰
    
    Args:
        lat1: ç¬¬ä¸€ä¸ªç‚¹çš„çº¬åº¦
        lon1: ç¬¬ä¸€ä¸ªç‚¹çš„ç»åº¦
        lat2: ç¬¬äºŒä¸ªç‚¹çš„çº¬åº¦
        lon2: ç¬¬äºŒä¸ªç‚¹çš„ç»åº¦
        
    Returns:
        ä¸¤ç‚¹é—´çš„è·ç¦»ï¼ˆç±³ï¼‰
    """
    R = 6371000  # åœ°çƒåŠå¾„ï¼ˆç±³ï¼‰
    phi1 = math.radians(lat1)
    phi2 = math.radians(lat2)
    delta_phi = math.radians(lat2 - lat1)
    delta_lambda = math.radians(lon2 - lon1)
    
    a = math.sin(delta_phi / 2) * math.sin(delta_phi / 2) + \
        math.cos(phi1) * math.cos(phi2) * \
        math.sin(delta_lambda / 2) * math.sin(delta_lambda / 2)
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    
    return R * c


def fuzzy_match(query: str, targets: List[str]) -> List[str]:
    """
    ç®€å•çš„æ¨¡ç³ŠåŒ¹é…å‡½æ•°
    
    Args:
        query: æŸ¥è¯¢å­—ç¬¦ä¸²
        targets: ç›®æ ‡å­—ç¬¦ä¸²åˆ—è¡¨
        
    Returns:
        åŒ¹é…åˆ°çš„å­—ç¬¦ä¸²åˆ—è¡¨
    """
    matched = []
    query_lower = query.lower()
    
    for target in targets:
        # ç²¾ç¡®åŒ¹é…
        if query_lower == target.lower():
            matched.append(target)
        # å‰ç¼€åŒ¹é…
        elif target.lower().startswith(query_lower):
            matched.append(target)
        # åŒ…å«åŒ¹é…
        elif query_lower in target.lower():
            matched.append(target)
        # ç¼–è¾‘è·ç¦»åŒ¹é…ï¼ˆç®€å•çš„ç›¸ä¼¼åº¦æ£€æŸ¥ï¼‰
        elif len(set(query_lower) & set(target.lower())) / max(len(query_lower), len(target.lower())) > 0.5:
            matched.append(target)
    
    return matched


def normalize_data(data: Dict[str, Any]) -> Dict[str, Any]:
    """
    æ ‡å‡†åŒ–æ•°æ®æ ¼å¼
    
    Args:
        data: åŸå§‹æ•°æ®å­—å…¸
        
    Returns:
        æ ‡å‡†åŒ–åçš„æ•°æ®å­—å…¸
    """
    normalized = {}
    
    # æ ‡å‡†åŒ–è¯„åˆ†
    detail_info = data.get("detail_info", {})
    for key in ["overall_rating", "taste_rating", "service_rating", "environment_rating"]:
        try:
            value = detail_info.get(key)
            normalized[key] = float(value) if value else 0.0
        except (ValueError, TypeError):
            normalized[key] = 0.0
    
    # æ ‡å‡†åŒ–ä»·æ ¼
    price = detail_info.get("price")
    try:
        normalized["price"] = float(price) if price else 0.0
    except (ValueError, TypeError):
        normalized["price"] = 0.0
    
    # æ ‡å‡†åŒ–æ•°å­—ç±»å‹æ•°æ®
    for key in ["comment_num", "favorite_num", "checkin_num"]:
        try:
            value = detail_info.get(key)
            normalized[key] = int(value) if value else 0
        except (ValueError, TypeError):
            normalized[key] = 0
    
    # å¤åˆ¶å…¶ä»–å­—æ®µ
    normalized.update({
        "name": data.get("name", ""),
        "address": data.get("address", ""),
        "telephone": data.get("telephone", ""),
        "location": data.get("location", {}),
        "uid": data.get("uid", ""),
        "tag": detail_info.get("tag", ""),
        "hours": detail_info.get("hours", ""),
        "description": detail_info.get("description", "")
    })
    
    return normalized


# ========== å·¥å…·å‡½æ•°ï¼ˆä» agent.py è¿ç§»ï¼‰ ==========

async def geocode_address(address: str, retries: int = 3) -> Dict[str, Any]:
    """
    åœ°å€ â†’ åæ ‡ (å¸¦é‡è¯•æœºåˆ¶)
    
    Args:
        address: åœ°å€å­—ç¬¦ä¸²
        retries: é‡è¯•æ¬¡æ•°
        
    Returns:
        åŒ…å«ç»çº¬åº¦ä¿¡æ¯çš„å­—å…¸
    """
    logger.info(f"æ­£åœ¨åœ°ç†ç¼–ç åœ°å€: {address}")
    url = f"{API_URL}/geocoding/v3/"
    
    for attempt in range(retries):
        try:
            params = {
                "ak": API_KEY,
                "output": "json",
                "address": address
            }
            resp = await http_client.get(url, params=params)
            resp.raise_for_status()
            result = resp.json()
            if result.get("status") != 0:
                logger.error(f"åœ°ç†ç¼–ç å¤±è´¥ï¼š{result.get('message')}")
                raise Exception(f"åœ°ç†ç¼–ç å¤±è´¥ï¼š{result.get('message')}")
            logger.info(f"åœ°ç†ç¼–ç æˆåŠŸ: {address}")
            return result["result"]["location"]
        except Exception as e:
            if attempt < retries - 1:
                logger.warning(f"åœ°ç†ç¼–ç è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {str(e)}")
                await asyncio.sleep(1 * (2 ** attempt))  # æŒ‡æ•°é€€é¿
            else:
                logger.error(f"åœ°ç†ç¼–ç è¯·æ±‚å¤±è´¥: {str(e)}")
                raise


async def search_places(
    query: str,
    latitude: float,
    longitude: float,
    radius: int = 1000,
    max_results: int = 10,
    tag: Optional[str] = None,
    price_section: Optional[str] = None,
    sort_name: Optional[str] = None,
    sort_rule: Optional[int] = None,
    groupon: Optional[str] = None,
    discount: Optional[str] = None,
    retries: int = 3
) -> List[Dict[str, Any]]:
    """
    åœ¨ç»™å®šåæ ‡åŠå¾„èŒƒå›´å†…,æ£€ç´¢å…³é”®å­— query çš„åœ°ç‚¹ï¼ˆå¦‚é¤å…ï¼‰(å¸¦é‡è¯•æœºåˆ¶å’Œå¢å¼ºå‚æ•°)
    
    Args:
        query: æœç´¢å…³é”®è¯
        latitude: çº¬åº¦
        longitude: ç»åº¦
        radius: æœç´¢åŠå¾„ï¼ˆç±³ï¼‰
        max_results: æœ€å¤§è¿”å›ç»“æœæ•°
        tag: æ ‡ç­¾ç­›é€‰
        price_section: ä»·æ ¼åŒºé—´
        sort_name: æ’åºå­—æ®µ
        sort_rule: æ’åºè§„åˆ™
        groupon: å›¢è´­ç­›é€‰
        discount: æŠ˜æ‰£ç­›é€‰
        retries: é‡è¯•æ¬¡æ•°
        
    Returns:
        åœ°ç‚¹æœç´¢ç»“æœåˆ—è¡¨
    """
    # å‚æ•°éªŒè¯
    if not (50 <= radius <= 50000):
        logger.warning(f"åŠå¾„ {radius} è¶…å‡ºåˆç†èŒƒå›´ [50, 50000]ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ 1000")
        radius = 1000
    
    if not (1 <= max_results <= 50):
        logger.warning(f"æœ€å¤§ç»“æœæ•° {max_results} è¶…å‡ºåˆç†èŒƒå›´ [1, 50]ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ 10")
        max_results = 10
    
    logger.info(f"æ­£åœ¨æœç´¢åœ°ç‚¹: {query}, ä½ç½®: ({latitude}, {longitude}), åŠå¾„: {radius}ç±³")
    url = f"{API_URL}/place/v2/search"
    location_str = f"{latitude},{longitude}"
    
    for attempt in range(retries):
        try:
            params = {
                "ak": API_KEY,
                "output": "json",
                "query": query,
                "location": location_str,
                "radius": radius,
                "scope": 2,  # è¿”å›è¾ƒè¯¦ç»†ä¿¡æ¯
                "filter": "industry_type:cater"  # é™å®šä¸ºé¤é¥®è¡Œä¸š
            }
            
            # æ·»åŠ æ ‡ç­¾ç­›é€‰
            if tag:
                params["tag"] = tag
                
            # æ·»åŠ ä»·æ ¼åŒºé—´ç­›é€‰
            if price_section:
                params["price_section"] = price_section
                
            # æ·»åŠ æ’åºå‚æ•°
            if sort_name:
                params["sort_name"] = sort_name
            if sort_rule is not None:
                params["sort_rule"] = sort_rule
                
            # æ·»åŠ å›¢è´­å’ŒæŠ˜æ‰£ç­›é€‰
            if groupon:
                params["groupon"] = groupon
            if discount:
                params["discount"] = discount
                
            resp = await http_client.get(url, params=params)
            resp.raise_for_status()
            result = resp.json()
            if result.get("status") != 0:
                logger.error(f"åœ°ç‚¹æ£€ç´¢å¤±è´¥ï¼š{result.get('message')}")
                raise Exception(f"åœ°ç‚¹æ£€ç´¢å¤±è´¥ï¼š{result.get('message')}")
            results = result.get("results", [])
            logger.info(f"æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
            return results[: max_results]
        except httpx.TimeoutException:
            if attempt < retries - 1:
                logger.warning(f"åœ°ç‚¹æœç´¢è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{retries})")
                await asyncio.sleep(1 * (2 ** attempt))  # æŒ‡æ•°é€€é¿
            else:
                logger.error("åœ°ç‚¹æœç´¢è¯·æ±‚è¶…æ—¶")
                raise Exception("åœ°ç‚¹æœç´¢è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
        except httpx.RequestError as e:
            if attempt < retries - 1:
                logger.warning(f"åœ°ç‚¹æœç´¢è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {str(e)}")
                await asyncio.sleep(1 * (2 ** attempt))  # æŒ‡æ•°é€€é¿
            else:
                logger.error(f"åœ°ç‚¹æœç´¢è¯·æ±‚å¤±è´¥: {str(e)}")
                raise Exception(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
        except Exception as e:
            if attempt < retries - 1:
                logger.warning(f"åœ°ç‚¹æœç´¢è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {str(e)}")
                await asyncio.sleep(1 * (2 ** attempt))  # æŒ‡æ•°é€€é¿
            else:
                logger.error(f"åœ°ç‚¹æœç´¢è¯·æ±‚å¤±è´¥: {str(e)}")
                raise


# ç¼“å­˜è£…é¥°å™¨ï¼Œç¼“å­˜10åˆ†é’Ÿ
@lru_cache(maxsize=128)
def _get_place_details_cache(uid: str, timestamp: int) -> str:
    """
    ç¼“å­˜placeè¯¦æƒ…çš„è¾…åŠ©å‡½æ•°ï¼Œtimestampå‚æ•°ç”¨äºæ§åˆ¶ç¼“å­˜æ—¶é—´
    
    Args:
        uid: åœ°ç‚¹UID
        timestamp: æ—¶é—´æˆ³
        
    Returns:
        ç¼“å­˜é”®å€¼
    """
    # è¿™åªæ˜¯ä¸€ä¸ªå ä½ç¬¦ï¼Œå®é™…ç¼“å­˜å®ç°åœ¨get_place_details_with_cacheä¸­
    pass


async def get_place_details_with_cache(uid: str, force_refresh: bool = False, retries: int = 3) -> Dict[str, Any]:
    """
    é€šè¿‡ uid è·å–æŸåœ°ç‚¹çš„è¯¦æƒ… (å¸¦ç¼“å­˜å’Œé‡è¯•æœºåˆ¶)
    
    Args:
        uid: åœ°ç‚¹UID
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
        retries: é‡è¯•æ¬¡æ•°
        
    Returns:
        åœ°ç‚¹è¯¦æƒ…ä¿¡æ¯
    """
    # æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
    if not force_refresh:
        # æ£€æŸ¥ç¼“å­˜ (5åˆ†é’Ÿæœ‰æ•ˆæœŸ)
        cache_key = f"{uid}_{int(time.time() // 300)}"  # ç¼©çŸ­ç¼“å­˜æ—¶é—´ä»¥å¢å¼ºå®æ—¶æ€§
        
        logger.info(f"æ­£åœ¨è·å–åœ°ç‚¹è¯¦æƒ…: {uid}")
    else:
        logger.info(f"å¼ºåˆ¶åˆ·æ–°åœ°ç‚¹è¯¦æƒ…: {uid}")
        
    url = f"{API_URL}/place/v2/detail"
    
    for attempt in range(retries):
        try:
            params = {
                "ak": API_KEY,
                "output": "json",
                "uid": uid,
                "scope": 2
            }
            resp = await http_client.get(url, params=params)
            resp.raise_for_status()
            result = resp.json()
            if result.get("status") != 0:
                logger.error(f"åœ°ç‚¹è¯¦æƒ…è·å–å¤±è´¥ï¼š{result.get('message')}")
                raise Exception(f"åœ°ç‚¹è¯¦æƒ…è·å–å¤±è´¥ï¼š{result.get('message')}")
            logger.info(f"åœ°ç‚¹è¯¦æƒ…è·å–æˆåŠŸ: {uid}")
            return result.get("result", {})
        except httpx.TimeoutException:
            if attempt < retries - 1:
                logger.warning(f"è·å–åœ°ç‚¹è¯¦æƒ…è¶…æ—¶ (å°è¯• {attempt + 1}/{retries})")
                await asyncio.sleep(1 * (2 ** attempt))  # æŒ‡æ•°é€€é¿
            else:
                logger.error("è·å–åœ°ç‚¹è¯¦æƒ…è¶…æ—¶")
                raise Exception("è·å–åœ°ç‚¹è¯¦æƒ…è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
        except httpx.RequestError as e:
            if attempt < retries - 1:
                logger.warning(f"è·å–åœ°ç‚¹è¯¦æƒ…å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {str(e)}")
                await asyncio.sleep(1 * (2 ** attempt))  # æŒ‡æ•°é€€é¿
            else:
                logger.error(f"è·å–åœ°ç‚¹è¯¦æƒ…å¤±è´¥: {str(e)}")
                raise Exception(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
        except Exception as e:
            if attempt < retries - 1:
                logger.warning(f"è·å–åœ°ç‚¹è¯¦æƒ…å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {str(e)}")
                await asyncio.sleep(1 * (2 ** attempt))  # æŒ‡æ•°é€€é¿
            else:
                logger.error(f"è·å–åœ°ç‚¹è¯¦æƒ…å¤±è´¥: {str(e)}")
                raise


async def get_place_details(uid: str) -> Dict[str, Any]:
    """
    é€šè¿‡ uid è·å–æŸåœ°ç‚¹çš„è¯¦æƒ… (å…¼å®¹æ—§æ¥å£)
    
    Args:
        uid: åœ°ç‚¹UID
        
    Returns:
        åœ°ç‚¹è¯¦æƒ…ä¿¡æ¯
    """
    return await get_place_details_with_cache(uid)


async def get_multiple_place_details(uids: List[str], force_refresh: bool = False) -> List[Dict[str, Any]]:
    """
    å¹¶å‘è·å–å¤šä¸ªåœ°ç‚¹è¯¦æƒ…
    
    Args:
        uids: åœ°ç‚¹UIDåˆ—è¡¨
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
        
    Returns:
        åœ°ç‚¹è¯¦æƒ…ä¿¡æ¯åˆ—è¡¨
    """
    tasks = [get_place_details_with_cache(uid, force_refresh) for uid in uids]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # å¤„ç†å¼‚å¸¸ç»“æœ
    processed_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            logger.warning(f"è·å–åœ°ç‚¹è¯¦æƒ…å¤±è´¥ (UID: {uids[i]}): {str(result)}")
            processed_results.append(None)
        else:
            processed_results.append(result)
    
    return processed_results


def calculate_composite_score(restaurant: Dict[str, Any], user_preferences: Optional[Dict[str, Any]] = None) -> float:
    """
    è®¡ç®—é¤å…çš„ç»¼åˆè¯„åˆ†ï¼Œè€ƒè™‘å¤šä¸ªå› ç´ 
    
    Args:
        restaurant: é¤å…ä¿¡æ¯å­—å…¸
        user_preferences: ç”¨æˆ·åå¥½è®¾ç½®
        
    Returns:
        ç»¼åˆè¯„åˆ†
    """
    detail_info = restaurant.get("detail_info", {})
    
    # åŸºç¡€è¯„åˆ†
    overall_rating = float(detail_info.get("overall_rating", 0) or 0)
    taste_rating = float(detail_info.get("taste_rating", 0) or 0)
    service_rating = float(detail_info.get("service_rating", 0) or 0)
    environment_rating = float(detail_info.get("environment_rating", 0) or 0)
    price = detail_info.get("price", None)
    
    # ç¤¾äº¤å±æ€§
    comment_num = int(detail_info.get("comment_num", 0) or 0)
    favorite_num = int(detail_info.get("favorite_num", 0) or 0)
    checkin_num = int(detail_info.get("checkin_num", 0) or 0)
    
    # ç”¨æˆ·è¯„ä»·
    uid = restaurant.get("uid", "")
    user_ratings = []
    if uid in user_reviews:
        user_ratings = [review["rating"] for review in user_reviews[uid]]
    
    # è®¡ç®—ç»¼åˆè¯„åˆ†
    # åŸºç¡€è¯„åˆ†æƒé‡ (50%)
    base_score = overall_rating
    if taste_rating > 0 or service_rating > 0 or environment_rating > 0:
        base_score = (taste_rating * 0.3 + service_rating * 0.2 + 
                     environment_rating * 0.2 + overall_rating * 0.3)
    
    # ç¤¾äº¤å±æ€§åŠ æƒ (25%)
    social_factor = min((comment_num + favorite_num * 2 + checkin_num) / 100, 10) / 10
    
    # ä»·æ ¼åˆç†æ€§ (15%)
    price_factor = 1.0
    if price:
        try:
            price_value = float(price)
            # ä»·æ ¼åœ¨50-200ä¹‹é—´è®¤ä¸ºæ˜¯åˆç†åŒºé—´ï¼Œç»™äºˆåŠ åˆ†
            if 50 <= price_value <= 200:
                price_factor = 1.1
            elif price_value > 500:
                price_factor = 0.9
        except ValueError:
            pass
    
    # ç”¨æˆ·è¯„ä»· (10%)
    user_rating_factor = 0.0
    if user_ratings:
        user_rating_factor = sum(user_ratings) / len(user_ratings) / 5.0  # æ ‡å‡†åŒ–åˆ°0-1
    
    # ç»¼åˆè¯„åˆ†è®¡ç®—
    composite_score = base_score * 0.5 + social_factor * 0.25 + price_factor * 0.15 + user_rating_factor * 0.1
    
    # å¦‚æœæœ‰ç”¨æˆ·åå¥½ï¼Œè¿›è¡Œä¸ªæ€§åŒ–è°ƒæ•´
    if user_preferences:
        # æ ¹æ®ç”¨æˆ·åå¥½è°ƒæ•´è¯„åˆ†
        preferred_cuisine = user_preferences.get("cuisine", "")
        if preferred_cuisine and preferred_cuisine in detail_info.get("tag", ""):
            composite_score *= 1.1  # åå¥½ç±»å‹åŠ æƒ
    
    return composite_score


# ========== MCP å·¥å…·å®šä¹‰ ==========

@mcp.tool()
async def recommend_food(
    address: str,
    cuisine_type: str = "é¤å…",
    radius: int = 1000,
    num_recommend: int = 5,
    price_range: Optional[str] = None,
    sort_by: Optional[str] = None,
    groupon_only: bool = False,
    discount_only: bool = False
) -> str:
    """
    æ ¹æ®åœ°å€å’Œèœç³»ç±»å‹æ¨èé™„è¿‘çš„é¤å…
    
    å‚æ•°:
        address: ç”¨æˆ·åœ°å€ï¼ˆå¦‚"åŒ—äº¬å¸‚æµ·æ·€åŒºä¸Šåœ°åè¡—10å·"ï¼‰
        cuisine_type: èœç³»ç±»å‹ï¼ˆå¦‚"ç«é”…"ã€"å·èœ"ã€"æ—¥æ–™"ç­‰ï¼Œé»˜è®¤"é¤å…"ï¼‰
        radius: æœç´¢åŠå¾„ï¼ˆç±³ï¼‰ï¼Œé»˜è®¤1000ç±³
        num_recommend: æ¨èæ•°é‡ï¼Œé»˜è®¤5ä¸ª
        price_range: ä»·æ ¼åŒºé—´ï¼Œå¦‚"0-50"ã€"50-100"ã€"100-200"ç­‰
        sort_by: æ’åºæ–¹å¼ï¼Œå¯é€‰: "rating"(è¯„åˆ†), "distance"(è·ç¦»), "price"(ä»·æ ¼)
        groupon_only: æ˜¯å¦åªæ˜¾ç¤ºæœ‰å›¢è´­çš„é¤å…
        discount_only: æ˜¯å¦åªæ˜¾ç¤ºæœ‰æŠ˜æ‰£çš„é¤å…
    
    è¿”å›:
        åŒ…å«æ¨èé¤å…åˆ—è¡¨çš„JSONå­—ç¬¦ä¸²
    """
    try:
        logger.info(f"å¼€å§‹æ¨èç¾é£Ÿ: åœ°å€={address}, èœç³»={cuisine_type}, åŠå¾„={radius}ç±³, æ•°é‡={num_recommend}")
        
        # å‚æ•°éªŒè¯
        if not address.strip():
            raise ValueError("åœ°å€ä¸èƒ½ä¸ºç©º")
            
        if not (50 <= radius <= 3000):
            logger.warning(f"æ¨èåŠå¾„ {radius} è¶…å‡ºå»ºè®®èŒƒå›´ [50, 3000]ï¼Œå¯èƒ½å½±å“ç»“æœè´¨é‡")
            
        if not (1 <= num_recommend <= 20):
            logger.warning(f"æ¨èæ•°é‡ {num_recommend} è¶…å‡ºåˆç†èŒƒå›´ [1, 20]ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ 5")
            num_recommend = 5
        
        # è§£æä»·æ ¼åŒºé—´
        price_section = None
        if price_range:
            if price_range == "0-50":
                price_section = "1"
            elif price_range == "50-100":
                price_section = "2"
            elif price_range == "100-200":
                price_section = "3"
            elif price_range == "200-400":
                price_section = "4"
            elif price_range == "400+":
                price_section = "5"
        
        # ç¡®å®šæ’åºæ–¹å¼
        sort_name = None
        sort_rule = None
        if sort_by == "price":
            sort_name = "price"
            sort_rule = 1  # å‡åº
        elif sort_by == "rating":
            sort_name = "overall_rating"
            sort_rule = 0  # é™åº
        
        # å›¢è´­å’ŒæŠ˜æ‰£å‚æ•°
        groupon_param = "1" if groupon_only else None
        discount_param = "1" if discount_only else None
        
        # 1. åœ°å€ â†’ åæ ‡
        loc = await geocode_address(address)
        lat = loc["lat"]
        lng = loc["lng"]
        
        # 2. æœç´¢å€™é€‰é¤å…
        candidates = await search_places(
            cuisine_type, 
            lat, 
            lng, 
            radius, 
            num_recommend * 3,  # å¢åŠ å€™é€‰æ•°é‡ä»¥æé«˜æ¨èè´¨é‡
            tag=cuisine_type,
            price_section=price_section,
            sort_name=sort_name,
            sort_rule=sort_rule,
            groupon=groupon_param,
            discount=discount_param
        )
        
        # 3. å¹¶å‘è·å–è¯¦æƒ… & å‡†å¤‡æ¨èæ•°æ®
        uids = [poi.get("uid") for poi in candidates if poi.get("uid")]
        detailed_results = await get_multiple_place_details(uids, force_refresh=True)
        
        detailed = []
        for i, det in enumerate(detailed_results):
            if det is None:
                continue
                
            uid = uids[i]
            detail_info = det.get("detail_info", {})
            
            # æ•°æ®æ ‡å‡†åŒ–
            normalized_data = normalize_data(det)
            
            info = {
                "name": normalized_data["name"],
                "address": normalized_data["address"],
                "telephone": normalized_data["telephone"],
                "rating": normalized_data["overall_rating"],
                "location": normalized_data["location"],
                "uid": normalized_data["uid"],
                # æ·»åŠ æ›´å¤šè¯„åˆ†ç»´åº¦
                "taste_rating": normalized_data["taste_rating"],
                "price": normalized_data["price"],
                "service_rating": normalized_data["service_rating"],
                "environment_rating": normalized_data["environment_rating"],
                # æ·»åŠ ç¤¾äº¤å±æ€§
                "comment_num": normalized_data["comment_num"],
                "favorite_num": normalized_data["favorite_num"],
                "checkin_num": normalized_data["checkin_num"],
                # æ·»åŠ å…¶ä»–æœ‰ç”¨ä¿¡æ¯
                "tag": normalized_data["tag"],
                "hours": normalized_data["hours"],
                "description": normalized_data["description"],
                # æ·»åŠ ç”¨æˆ·è¯„ä»·ä¿¡æ¯
                "user_reviews": user_reviews.get(uid, [])
            }
            
            # ä½¿ç”¨ Haversine å…¬å¼è®¡ç®—ç²¾ç¡®è·ç¦»
            if info["location"]:
                info["distance_m"] = round(haversine_distance(
                    lat, lng, 
                    info["location"]["lat"], 
                    info["location"]["lng"]
                ))
            else:
                info["distance_m"] = None
            detailed.append(info)

        # 4. æ’åºï¼šç»¼åˆè¯„åˆ†é™åº + è·ç¦»è¿‘ä¼˜å…ˆ
        def sort_key(x):
            composite_score = calculate_composite_score(x)
            # å¦‚æœæŒ‡å®šäº†æ’åºæ–¹å¼ï¼Œåˆ™æŒ‰æŒ‡å®šæ–¹å¼æ’åº
            if sort_by == "distance":
                return (x.get("distance_m") or 999999)
            elif sort_by == "price":
                try:
                    price = float(x.get("price") or 0)
                    return (price, -composite_score)
                except ValueError:
                    return (999999, -composite_score)
            elif sort_by == "rating":
                return (-composite_score)
            else:
                # é»˜è®¤æ’åºï¼šç»¼åˆè¯„åˆ†ä¸ºä¸»ï¼Œè·ç¦»ä¸ºè¾…
                return (-composite_score, x.get("distance_m") or 999999)
            
        detailed.sort(key=sort_key)
        top = detailed[: num_recommend]

        # è¿”å›ç»“æ„
        result = {
            "query_address": address,
            "cuisine_type": cuisine_type,
            "radius_m": radius,
            "price_range": price_range,
            "sort_by": sort_by,
            "groupon_only": groupon_only,
            "discount_only": discount_only,
            "recommendations": top
        }
        
        # æ ¼å¼åŒ–è¾“å‡º
        import json
        output = json.dumps(result, ensure_ascii=False, indent=2)
        logger.info(f"æ¨èå®Œæˆï¼Œè¿”å› {len(top)} ä¸ªç»“æœ")
        return output
        
    except Exception as e:
        logger.error(f"æ¨èå¤±è´¥: {str(e)}")
        return f"æ¨èå¤±è´¥: {str(e)}"


@mcp.tool()
async def search_nearby_restaurants(
    address: str,
    keyword: str = "é¤å…",
    radius: int = 1000,
    max_results: int = 10,
    price_range: Optional[str] = None,
    sort_by: Optional[str] = None,
    fuzzy_search: bool = False
) -> str:
    """
    æœç´¢æŒ‡å®šåœ°å€é™„è¿‘çš„é¤å…
    
    å‚æ•°:
        address: æœç´¢åœ°å€
        keyword: æœç´¢å…³é”®è¯ï¼ˆé»˜è®¤"é¤å…"ï¼‰
        radius: æœç´¢åŠå¾„ï¼ˆç±³ï¼‰ï¼Œé»˜è®¤1000ç±³
        max_results: æœ€å¤šè¿”å›ç»“æœæ•°ï¼Œé»˜è®¤10ä¸ª
        price_range: ä»·æ ¼åŒºé—´ï¼Œå¦‚"0-50"ã€"50-100"ã€"100-200"ç­‰
        sort_by: æ’åºæ–¹å¼ï¼Œå¯é€‰: "rating"(è¯„åˆ†), "distance"(è·ç¦»), "price"(ä»·æ ¼)
        fuzzy_search: æ˜¯å¦å¯ç”¨æ¨¡ç³Šæœç´¢
    
    è¿”å›:
        é™„è¿‘é¤å…åˆ—è¡¨çš„JSONå­—ç¬¦ä¸²
    """
    try:
        logger.info(f"å¼€å§‹æœç´¢é™„è¿‘é¤å…: åœ°å€={address}, å…³é”®è¯={keyword}, åŠå¾„={radius}ç±³, æœ€å¤§ç»“æœæ•°={max_results}")
        
        # å‚æ•°éªŒè¯
        if not address.strip():
            raise ValueError("åœ°å€ä¸èƒ½ä¸ºç©º")
            
        if not (50 <= radius <= 3000):
            logger.warning(f"æœç´¢åŠå¾„ {radius} è¶…å‡ºå»ºè®®èŒƒå›´ [50, 3000]ï¼Œå¯èƒ½å½±å“ç»“æœè´¨é‡")
            
        if not (1 <= max_results <= 20):
            logger.warning(f"æœ€å¤§ç»“æœæ•° {max_results} è¶…å‡ºåˆç†èŒƒå›´ [1, 20]ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ 10")
            max_results = 10
            
        # è§£æä»·æ ¼åŒºé—´
        price_section = None
        if price_range:
            if price_range == "0-50":
                price_section = "1"
            elif price_range == "50-100":
                price_section = "2"
            elif price_range == "100-200":
                price_section = "3"
            elif price_range == "200-400":
                price_section = "4"
            elif price_range == "400+":
                price_section = "5"
        
        # ç¡®å®šæ’åºæ–¹å¼
        sort_name = None
        sort_rule = None
        if sort_by == "price":
            sort_name = "price"
            sort_rule = 1  # å‡åº
        elif sort_by == "rating":
            sort_name = "overall_rating"
            sort_rule = 0  # é™åº
            
        # åœ°å€è½¬åæ ‡
        loc = await geocode_address(address)
        lat = loc["lat"]
        lng = loc["lng"]
        
        # å¦‚æœå¯ç”¨æ¨¡ç³Šæœç´¢ï¼Œæ‰©å±•å…³é”®è¯
        search_keywords = [keyword]
        if fuzzy_search:
            # è¿™é‡Œå¯ä»¥æ·»åŠ å¸¸è§çš„é¤å…ç±»å‹è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
            common_cuisines = [
                "ä¸­é¤", "è¥¿é¤", "æ—¥æ–™", "éŸ©æ–™", "ç«é”…", "çƒ§çƒ¤", 
                "å·èœ", "ç²¤èœ", "æ¹˜èœ", "é²èœ", "æµ™èœ", "é—½èœ", 
                "è‹èœ", "å¾½èœ", "å¿«é¤", "å°åƒ", "ç”œå“", "å’–å•¡"
            ]
            fuzzy_matches = fuzzy_match(keyword, common_cuisines)
            search_keywords.extend(fuzzy_matches)
            logger.info(f"æ¨¡ç³Šæœç´¢åŒ¹é…åˆ°å…³é”®è¯: {fuzzy_matches}")
        
        # æœç´¢åœ°ç‚¹
        all_places = []
        for search_keyword in search_keywords:
            try:
                places = await search_places(
                    search_keyword, 
                    lat, 
                    lng, 
                    radius, 
                    max_results,
                    price_section=price_section,
                    sort_name=sort_name,
                    sort_rule=sort_rule
                )
                all_places.extend(places)
            except Exception as e:
                logger.warning(f"ä½¿ç”¨å…³é”®è¯ '{search_keyword}' æœç´¢å¤±è´¥: {str(e)}")
                continue
        
        # å»é‡å¤„ç†
        unique_places = []
        seen_uids = set()
        for place in all_places:
            uid = place.get("uid")
            if uid and uid not in seen_uids:
                unique_places.append(place)
                seen_uids.add(uid)
        
        # ç®€åŒ–ç»“æœ
        results = []
        for place in unique_places[:max_results]:
            detail_info = place.get("detail_info", {})
            # æ•°æ®æ ‡å‡†åŒ–
            normalized_data = normalize_data(place)
            
            results.append({
                "name": normalized_data["name"],
                "address": normalized_data["address"],
                "uid": normalized_data["uid"],
                "location": normalized_data["location"],
                # æ·»åŠ è¯„åˆ†ä¿¡æ¯
                "rating": normalized_data["overall_rating"],
                "price": normalized_data["price"],
                # æ·»åŠ ç¤¾äº¤å±æ€§
                "comment_num": normalized_data["comment_num"],
                "tag": normalized_data["tag"],
                # æ·»åŠ ç”¨æˆ·è¯„ä»·ä¿¡æ¯
                "user_reviews": user_reviews.get(normalized_data["uid"], [])
            })
        
        import json
        result = {
            "address": address,
            "keyword": keyword,
            "fuzzy_search": fuzzy_search,
            "radius_m": radius,
            "price_range": price_range,
            "sort_by": sort_by,
            "results": results
        }
        output = json.dumps(result, ensure_ascii=False, indent=2)
        logger.info(f"æœç´¢å®Œæˆï¼Œè¿”å› {len(results)} ä¸ªç»“æœ")
        return output
        
    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {str(e)}")
        return f"æœç´¢å¤±è´¥: {str(e)}"


@mcp.tool()
async def get_restaurant_details(uid: str, refresh: bool = False) -> str:
    """
    è·å–é¤å…è¯¦ç»†ä¿¡æ¯
    
    å‚æ•°:
        uid: é¤å…çš„å”¯ä¸€æ ‡è¯†ç¬¦
        refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜æ•°æ®
    
    è¿”å›:
        é¤å…è¯¦ç»†ä¿¡æ¯çš„JSONå­—ç¬¦ä¸²
    """
    try:
        logger.info(f"å¼€å§‹è·å–é¤å…è¯¦æƒ…: UID={uid}")
        
        # å‚æ•°éªŒè¯
        if not uid.strip():
            raise ValueError("é¤å… UID ä¸èƒ½ä¸ºç©º")
            
        details = await get_place_details_with_cache(uid, force_refresh=refresh)
        # æ·»åŠ ç”¨æˆ·è¯„ä»·ä¿¡æ¯
        details["user_reviews"] = user_reviews.get(uid, [])
        
        import json
        output = json.dumps(details, ensure_ascii=False, indent=2)
        logger.info(f"è·å–é¤å…è¯¦æƒ…æˆåŠŸ: UID={uid}")
        return output
    except Exception as e:
        logger.error(f"è·å–è¯¦æƒ…å¤±è´¥: {str(e)}")
        return f"è·å–è¯¦æƒ…å¤±è´¥: {str(e)}"


@mcp.tool()
async def compare_restaurants(uids: List[str]) -> str:
    """
    å¯¹æ¯”å¤šä¸ªé¤å…çš„ä¿¡æ¯
    
    å‚æ•°:
        uids: é¤å…çš„å”¯ä¸€æ ‡è¯†ç¬¦åˆ—è¡¨
    
    è¿”å›:
        é¤å…å¯¹æ¯”ä¿¡æ¯çš„JSONå­—ç¬¦ä¸²
    """
    try:
        logger.info(f"å¼€å§‹å¯¹æ¯”é¤å…: UIDs={uids}")
        
        # å‚æ•°éªŒè¯
        if not uids:
            raise ValueError("è‡³å°‘éœ€è¦ä¸€ä¸ªé¤å… UID")
        
        if len(uids) > 10:
            raise ValueError("æœ€å¤šåªèƒ½åŒæ—¶å¯¹æ¯”10ä¸ªé¤å…")
        
        # è·å–æ‰€æœ‰é¤å…è¯¦æƒ…
        restaurant_details = await get_multiple_place_details(uids)
        
        # å‡†å¤‡å¯¹æ¯”æ•°æ®
        comparison_data = []
        for i, detail in enumerate(restaurant_details):
            if detail is None:
                continue
                
            uid = uids[i]
            detail_info = detail.get("detail_info", {})
            # æ•°æ®æ ‡å‡†åŒ–
            normalized_data = normalize_data(detail)
            
            # æ·»åŠ ç”¨æˆ·è¯„ä»·ç»Ÿè®¡
            user_review_count = len(user_reviews.get(uid, []))
            user_average_rating = 0
            representative_reviews = []
            if user_reviews.get(uid):
                user_average_rating = sum([r["rating"] for r in user_reviews.get(uid, [])]) / len(user_reviews.get(uid, []))
                # é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„è¯„ä»·ï¼ˆæœ€é«˜åˆ†å’Œæœ€ä½åˆ†å„é€‰ä¸€æ¡ï¼Œæœ€å¤š2æ¡ï¼‰
                sorted_reviews = sorted(user_reviews[uid], key=lambda x: x["rating"], reverse=True)
                if sorted_reviews:
                    representative_reviews.append(sorted_reviews[0])  # æœ€é«˜åˆ†è¯„ä»·
                    if len(sorted_reviews) > 1:
                        representative_reviews.append(sorted_reviews[-1])  # æœ€ä½åˆ†è¯„ä»·
            
            comparison_data.append({
                "uid": uid,
                "name": normalized_data["name"],
                "address": normalized_data["address"],
                "rating": normalized_data["overall_rating"],
                "taste_rating": normalized_data["taste_rating"],
                "service_rating": normalized_data["service_rating"],
                "environment_rating": normalized_data["environment_rating"],
                "price": normalized_data["price"],
                "comment_num": normalized_data["comment_num"],
                "favorite_num": normalized_data["favorite_num"],
                "checkin_num": normalized_data["checkin_num"],
                "tag": normalized_data["tag"],
                "hours": normalized_data["hours"],
                "user_review_count": user_review_count,
                "user_average_rating": user_average_rating,
                "representative_reviews": representative_reviews  # æ·»åŠ ä»£è¡¨æ€§è¯„ä»·
            })
        
        # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
        comparison_data.sort(key=lambda x: calculate_composite_score({"detail_info": {
            "overall_rating": x["rating"],
            "taste_rating": x["taste_rating"],
            "service_rating": x["service_rating"],
            "environment_rating": x["environment_rating"],
            "price": x["price"],
            "comment_num": x["comment_num"],
            "favorite_num": x["favorite_num"],
            "checkin_num": x["checkin_num"]
        }}), reverse=True)
        
        result = {
            "comparison": comparison_data,
            "count": len(comparison_data)
        }
        
        import json
        output = json.dumps(result, ensure_ascii=False, indent=2)
        logger.info(f"é¤å…å¯¹æ¯”å®Œæˆï¼Œå…±å¯¹æ¯” {len(comparison_data)} ä¸ªé¤å…")
        return output
    except Exception as e:
        logger.error(f"é¤å…å¯¹æ¯”å¤±è´¥: {str(e)}")
        return f"é¤å…å¯¹æ¯”å¤±è´¥: {str(e)}"


@mcp.tool()
async def generate_restaurant_map(
    uids: List[str],
    width: int = 400,
    height: int = 300,
    zoom: int = 15
) -> str:
    """
    ä¸ºæŒ‡å®šUIDçš„é¤å…ç”Ÿæˆå¸¦æ ‡è®°çš„åœ°å›¾å›¾ç‰‡
    
    å‚æ•°:
        uids: é¤å…çš„å”¯ä¸€æ ‡è¯†ç¬¦åˆ—è¡¨
        width: å›¾ç‰‡å®½åº¦ï¼Œé»˜è®¤400åƒç´ 
        height: å›¾ç‰‡é«˜åº¦ï¼Œé»˜è®¤300åƒç´ 
        zoom: åœ°å›¾ç¼©æ”¾çº§åˆ«ï¼Œé»˜è®¤15
    
    è¿”å›:
        åŒ…å«åœ°å›¾å›¾ç‰‡URLå’Œé¤å…ä½ç½®ä¿¡æ¯çš„JSONå­—ç¬¦ä¸²
    """
    try:
        logger.info(f"å¼€å§‹ç”Ÿæˆé¤å…åœ°å›¾: UIDs={uids}")
        
        # å‚æ•°éªŒè¯
        if not uids:
            raise ValueError("è‡³å°‘éœ€è¦ä¸€ä¸ªé¤å… UID")
            
        if len(uids) > 10:
            raise ValueError("æœ€å¤šåªèƒ½åŒæ—¶æ˜¾ç¤º10ä¸ªé¤å…ä½ç½®")
            
        if not (200 <= width <= 1000):
            logger.warning(f"å›¾ç‰‡å®½åº¦ {width} è¶…å‡ºå»ºè®®èŒƒå›´ [200, 1000]ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ 400")
            width = 400
            
        if not (200 <= height <= 1000):
            logger.warning(f"å›¾ç‰‡é«˜åº¦ {height} è¶…å‡ºå»ºè®®èŒƒå›´ [200, 1000]ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ 300")
            height = 300
            
        if not (3 <= zoom <= 19):
            logger.warning(f"ç¼©æ”¾çº§åˆ« {zoom} è¶…å‡ºå»ºè®®èŒƒå›´ [3, 19]ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ 15")
            zoom = 15
        
        # è·å–æ‰€æœ‰é¤å…è¯¦æƒ…
        restaurant_details_list = await get_multiple_place_details(uids)
        
        # è¿‡æ»¤æ‰è·å–å¤±è´¥çš„é¤å…è¯¦æƒ…
        valid_restaurants = []
        for i, details in enumerate(restaurant_details_list):
            if details is None:
                logger.warning(f"æ— æ³•è·å–é¤å…è¯¦æƒ…: UID={uids[i]}")
                continue
                
            location = details.get("location")
            if not location:
                logger.warning(f"é¤å…ä½ç½®ä¿¡æ¯ä¸å¯ç”¨: UID={uids[i]}")
                continue
                
            lat = location.get("lat")
            lng = location.get("lng")
            
            if not lat or not lng:
                logger.warning(f"é¤å…ä½ç½®åæ ‡ä¸å®Œæ•´: UID={uids[i]}")
                continue
                
            valid_restaurants.append({
                "uid": uids[i],
                "name": details.get("name", "æœªçŸ¥é¤å…"),
                "latitude": lat,
                "longitude": lng
            })
        
        if not valid_restaurants:
            return "æ²¡æœ‰æœ‰æ•ˆçš„é¤å…ä½ç½®ä¿¡æ¯å¯ç”¨äºç”Ÿæˆåœ°å›¾"
        
        # è®¡ç®—ä¸­å¿ƒç‚¹ï¼ˆå¦‚æœæœ‰å¤šä¸ªé¤å…ï¼‰
        center_lat, center_lng = _calculate_center_point(valid_restaurants)
        
        # æ„é€ æ ‡è®°ç‚¹å­—ç¬¦ä¸²
        marker_points = _build_marker_points(valid_restaurants)
        
        # ç”Ÿæˆé™æ€åœ°å›¾URL
        map_url = _generate_static_map_url(
            center_lat, center_lng, width, height, zoom, marker_points
        )
        
        result = {
            "map_url": map_url,
            "restaurants": valid_restaurants,
            "center_latitude": center_lat,
            "center_longitude": center_lng,
            "width": width,
            "height": height,
            "zoom": zoom
        }
        
        import json
        output = json.dumps(result, ensure_ascii=False, indent=2)
        logger.info(f"æˆåŠŸç”Ÿæˆé¤å…åœ°å›¾ï¼ŒåŒ…å« {len(valid_restaurants)} ä¸ªé¤å…ä½ç½®")
        return output
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆé¤å…åœ°å›¾å¤±è´¥: {str(e)}")
        return f"ç”Ÿæˆé¤å…åœ°å›¾å¤±è´¥: {str(e)}"


def _calculate_center_point(valid_restaurants: List[Dict[str, Any]]) -> tuple:
    """
    è®¡ç®—å¤šä¸ªé¤å…ä½ç½®çš„ä¸­å¿ƒç‚¹
    
    å‚æ•°:
        valid_restaurants: æœ‰æ•ˆé¤å…åˆ—è¡¨
        
    è¿”å›:
        (ä¸­å¿ƒçº¬åº¦, ä¸­å¿ƒç»åº¦) å…ƒç»„
    """
    if len(valid_restaurants) == 1:
        restaurant = valid_restaurants[0]
        return restaurant["latitude"], restaurant["longitude"]
    else:
        # è®¡ç®—æ‰€æœ‰æœ‰æ•ˆé¤å…çš„ä¸­å¿ƒç‚¹
        avg_lat = sum(r["latitude"] for r in valid_restaurants) / len(valid_restaurants)
        avg_lng = sum(r["longitude"] for r in valid_restaurants) / len(valid_restaurants)
        return avg_lat, avg_lng


def _build_marker_points(valid_restaurants: List[Dict[str, Any]]) -> str:
    """
    æ„é€ åœ°å›¾æ ‡è®°ç‚¹å­—ç¬¦ä¸²
    
    å‚æ•°:
        valid_restaurants: æœ‰æ•ˆé¤å…åˆ—è¡¨
        
    è¿”å›:
        æ ‡è®°ç‚¹å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º "lng1,lat1|lng2,lat2|..."
    """
    marker_points = []
    for restaurant in valid_restaurants:
        marker_points.append(f"{restaurant['longitude']},{restaurant['latitude']}")
    return "|".join(marker_points)


def _generate_static_map_url(
    center_lat: float, 
    center_lng: float, 
    width: int, 
    height: int, 
    zoom: int, 
    markers: str
) -> str:
    """
    ç”Ÿæˆé™æ€åœ°å›¾URL
    
    å‚æ•°:
        center_lat: ä¸­å¿ƒç‚¹çº¬åº¦
        center_lng: ä¸­å¿ƒç‚¹ç»åº¦
        width: å›¾ç‰‡å®½åº¦
        height: å›¾ç‰‡é«˜åº¦
        zoom: ç¼©æ”¾çº§åˆ«
        markers: æ ‡è®°ç‚¹å­—ç¬¦ä¸²
        
    è¿”å›:
        å®Œæ•´çš„é™æ€åœ°å›¾URL
    """
    from urllib.parse import urlencode
    
    map_url = f"{API_URL}/staticimage/v2"
    params = {
        "ak": API_KEY,
        "center": f"{center_lng},{center_lat}",
        "width": width,
        "height": height,
        "zoom": zoom,
        "markers": markers,
        "markerStyles": "l,A"
    }
    
    return f"{map_url}?{urlencode(params)}"


# ========== è¿è¡ŒæœåŠ¡å™¨ ==========

def main():
    """å¯åŠ¨MCPæœåŠ¡å™¨"""
    logger.info("="*60)
    logger.info("ğŸœ ç¾é£Ÿæ¨èMCPæœåŠ¡å™¨å¯åŠ¨")
    logger.info("="*60)
    
    # è·å–ç«¯å£é…ç½®ï¼ˆé˜¿é‡Œäº‘å‡½æ•°è®¡ç®—ä½¿ç”¨ PORT ç¯å¢ƒå˜é‡ï¼‰
    port = int(os.environ.get("MCP_PORT", os.environ.get("PORT", "9000")))
    
    logger.info(f"[SSEæ¨¡å¼] å¯åŠ¨ MCP æœåŠ¡å™¨")
    logger.info(f"[SSEæ¨¡å¼] ç›‘å¬åœ°å€: http://localhost:{port}/sse")
    logger.info(f"[SSEæ¨¡å¼] ç½‘ç»œåœ°å€: http://0.0.0.0:{port}/sse")
    logger.info(f"[SSEæ¨¡å¼] ä½¿ç”¨ Ctrl+C åœæ­¢æœåŠ¡å™¨")
    logger.info("-" * 60)
    
    # å¯åŠ¨MCPæœåŠ¡å™¨
    # FastMCP 2.5+ ç‰ˆæœ¬æ”¯æŒ host/port å‚æ•°
    mcp.run(
        transport="sse",
        host="0.0.0.0",
        port=port,
        path="/sse",
        log_level="info",
    )


if __name__ == "__main__":
    main()
